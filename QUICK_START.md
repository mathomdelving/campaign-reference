# Quick Start Guide

**Get up and running with FEC data collection in 5 minutes.**

---

## üöÄ Collect FEC Data (2-Step Workflow)

### Step 1: Collect ‚Üí JSON Files

```bash
# Use the canonical robust collection script
python3 scripts/collect_cycle_data.py --cycle 2024 --max-retries 3
```

**What it does:**
- Collects ALL House & Senate candidates for the specified cycle
- Fetches financial summaries and ALL report types (quarterly + pre/post election)
- Uses **historical committee designations** (correct for the target cycle)
- Automatically retries failures with exponential backoff
- Saves progress every 50 candidates (can resume if interrupted)
- Creates JSON files for review before upload

**Output files:**
- `candidates_{cycle}.json`
- `financials_{cycle}.json`
- `quarterly_financials_{cycle}.json`
- `failures_{cycle}.json` (if any persistent failures)
- `no_data_{cycle}.json` (transparency file)

### Step 2: Review ‚Üí Upload to Supabase

```bash
# Review the JSON files first
ls -lh *_2024.json
head -20 candidates_2024.json

# Then upload to database
python3 scripts/data-loading/load_to_supabase.py
```

**That's it!** Always follow this 2-step workflow.

---

## ‚è±Ô∏è Background Execution (for long-running collections)

```bash
# Run in background with caffeinate to prevent sleep
nohup caffeinate -i python3 -u scripts/collect_cycle_data.py --cycle 2022 --max-retries 3 > collection_2022.log 2>&1 &

# Monitor progress
tail -f collection_2022.log

# Check if still running
ps aux | grep collect_cycle_data
```

---

## üìñ Key Features

**‚úÖ Robust Error Handling:**
- Exponential backoff retry for rate limits and timeouts
- Automatic retry passes (up to 3) for failed candidates
- All errors tracked and logged

**‚úÖ Complete Data Collection:**
- ALL report types: quarterly, pre-primary, pre-general, post-general, etc.
- No designation filters: captures P, U, A, J, D committees
- Historical designations: uses contemporaneous values, not current state

**‚úÖ Resume Capability:**
- Progress saved every 50 candidates
- Can restart from crashes without losing work
- Checkpoint files cleaned up on success

**‚úÖ Data Integrity:**
- 2-step workflow ensures human review before upload
- JSON files serve as backup and audit trail
- No silent failures (all errors tracked)

---

## üìö Documentation

- **Complete workflow:** [docs/DATA_COLLECTION_WORKFLOW.md](docs/DATA_COLLECTION_WORKFLOW.md)
- **Collection guide:** [docs/guides/collection-guide.md](docs/guides/collection-guide.md)
- **FEC API reference:** [docs/data/FEC_API_GUIDE.md](docs/data/FEC_API_GUIDE.md)
- **All documentation:** [docs/README.md](docs/README.md)

---

## üéØ Common Commands

```bash
# Collect 2024 data
python3 scripts/collect_cycle_data.py --cycle 2024 --max-retries 3

# Collect 2022 historical data
python3 scripts/collect_cycle_data.py --cycle 2022 --max-retries 3

# Upload to Supabase (after reviewing JSON)
python3 scripts/data-loading/load_to_supabase.py

# Count records in JSON
python3 -c "import json; data=json.load(open('quarterly_financials_2024.json')); print(f'{len(data):,} filings')"
```

---

**‚≠ê Always use:** `scripts/collect_cycle_data.py` for data collection.

This is the canonical, robust, battle-tested script with:
- ‚úÖ 100% success rate (with automatic retries)
- ‚úÖ Historical designation accuracy
- ‚úÖ Complete report type coverage
- ‚úÖ Resume capability

**Last Updated:** November 22, 2025
